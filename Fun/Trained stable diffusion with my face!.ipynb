{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i3GhhZmvhfxS"
   },
   "source": [
    "#⭐ **DreamBooth colab From https://github.com/TheLastBen/fast-stable-diffusion**\n",
    "###🛠️ Notebook adaptado por [@dotcsv](https://www.youtube.com/channel/UCy5znSnfMsDwaLlROnZ7Qbg). Actualizado a Python 3.8 por [@Deus;Gate](https://www.youtube.com/channel/UCNojH61Q5RcbBWSLW1UjTkw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f-BcD0b8hwdA"
   },
   "source": [
    "[texto del enlace](https://)🚨 Ten activada la **Aceleración por hardware** con GPU en `\"Entorno de ejecución\" > \"Cambiar tipo de entorno de ejecución\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 710,
     "status": "ok",
     "timestamp": 1673396105975,
     "user": {
      "displayName": "franciscopinelli",
      "userId": "17406683420579142537"
     },
     "user_tz": 180
    },
    "id": "cUUnmQGHm3a4",
    "outputId": "6a8c350d-3c45-4a03-d0e0-8ce3f594f6a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 0: Tesla T4 (UUID: GPU-bfd0618b-48f5-0329-d6d5-cfc63db705bd)\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi -L"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WCgtpGr6ZOyG"
   },
   "source": [
    "### **Paso 1** - Conectamos con Google Drive. **Importante contar con unos 4GB de almacenamiento.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1963,
     "status": "ok",
     "timestamp": 1673396111200,
     "user": {
      "displayName": "franciscopinelli",
      "userId": "17406683420579142537"
     },
     "user_tz": 180
    },
    "id": "A4Bae3VP6UsE",
    "outputId": "6443f6e8-24d7-4031-ef29-36d99faa59a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bbKbx185zqlz"
   },
   "source": [
    "### **Paso 2** - Instalamos las librerías necesarias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QyvcqeiL65Tj",
    "outputId": "0df4f422-1252-437e-cedf-20998973a23d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing dependencies...\n"
     ]
    }
   ],
   "source": [
    "#@markdown # Dependencies\n",
    "\n",
    "from IPython.utils import capture\n",
    "from subprocess import getoutput\n",
    "import time\n",
    "\n",
    "print('Installing dependencies...')\n",
    "with capture.capture_output() as cap:\n",
    "    %cd /content/\n",
    "    !pip install -q accelerate==0.12.0\n",
    "    for i in range(1,6):\n",
    "        !wget -q \"https://github.com/TheLastBen/fast-stable-diffusion/raw/main/Dependencies/Dependencies.{i}\"\n",
    "        !mv \"Dependencies.{i}\" \"Dependencies.7z.00{i}\"\n",
    "    !7z x -y Dependencies.7z.001\n",
    "    time.sleep(2)\n",
    "    %cd /content/usr/local/lib/python3.8/dist-packages\n",
    "    !rm -r PIL Pillow.libs Pillow-9.3.0.dist-info\n",
    "    !cp -r /content/usr/local/lib/python3.8/dist-packages /usr/local/lib/python3.8/\n",
    "    !rm -r /content/usr\n",
    "    %cd /content\n",
    "    for i in range(1,6):\n",
    "        !rm \"Dependencies.7z.00{i}\"\n",
    "    !pip uninstall -y diffusers\n",
    "    !git clone --branch updt https://github.com/TheLastBen/diffusers\n",
    "    !pip install -q /content/diffusers\n",
    "    s = getoutput('nvidia-smi')\n",
    "    if \"A100\" in s:\n",
    "        !wget https://github.com/TheLastBen/fast-stable-diffusion/raw/main/precompiled/A100/A100\n",
    "        %cd /usr/local/lib/python3.8/dist-packages/xformers\n",
    "        !7z x -y /content/A100\n",
    "        !rm /content/A100\n",
    "        %cd /content/\n",
    "print('Ahora funciona, dale gracias a eltiolucas y a jorgebarrios9648 ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BJ93IWS87TgU"
   },
   "outputs": [],
   "source": [
    "!pip install wget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CnBAZ4eje2Sl"
   },
   "source": [
    "### **Paso 3** - Descargamos el modelo .ckpt de Stable Diffusion original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7266,
     "status": "ok",
     "timestamp": 1673392747841,
     "user": {
      "displayName": "franciscopinelli",
      "userId": "17406683420579142537"
     },
     "user_tz": 180
    },
    "id": "VAY8R-EMn9Zb",
    "outputId": "e85bee9d-8612-415f-e139-8ae3090a4295"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: wget in /usr/local/lib/python3.8/dist-packages (3.2)\n",
      "\u001b[1;32mThe v1.5 model already exists, using this model.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "from IPython.utils import capture\n",
    "import wget\n",
    "\n",
    "#@markdown - Skip this cell if you are loading a previous session\n",
    "\n",
    "#@markdown ---\n",
    "\n",
    "Model_Version = \"1.5\"\n",
    "\n",
    "with capture.capture_output() as cap:\n",
    "  %cd /content/\n",
    "\n",
    "Huggingface_Token = \"Here i used my token, of course i can not make it public\" #@param {type:\"string\"}\n",
    "token=Huggingface_Token\n",
    "\n",
    "#@markdown - Make sure you've accepted the terms in https://huggingface.co/runwayml/stable-diffusion-v1-5\n",
    "\n",
    "#@markdown ---\n",
    "\n",
    "Path_to_HuggingFace= \"\" #@param {type:\"string\"}\n",
    "\n",
    "#@markdown Or\n",
    "\n",
    "CKPT_Path = \"\" #@param {type:\"string\"}\n",
    "\n",
    "#@markdown Or\n",
    "\n",
    "CKPT_Link = \"\" #@param {type:\"string\"}\n",
    "\n",
    "#@markdown - A CKPT direct link, huggingface CKPT link or a shared CKPT from gdrive.\n",
    "#@markdown ---\n",
    "\n",
    "Compatibility_Mode=False #@param {type:\"boolean\"}\n",
    "#@markdown - Enable only if you're getting conversion errors.\n",
    "\n",
    "\n",
    "def downloadmodel():\n",
    "  token=Huggingface_Token\n",
    "  if token==\"\":\n",
    "      token=input(\"Insert your huggingface token :\")\n",
    "  if os.path.exists('/content/stable-diffusion-v1-5'):\n",
    "    !rm -r /content/stable-diffusion-v1-5\n",
    "  clear_output()\n",
    "\n",
    "  %cd /content/\n",
    "  clear_output()\n",
    "  !mkdir /content/stable-diffusion-v1-5\n",
    "  %cd /content/stable-diffusion-v1-5\n",
    "  !git init\n",
    "  !git lfs install --system --skip-repo\n",
    "  !git remote add -f origin  \"https://USER:{token}@huggingface.co/runwayml/stable-diffusion-v1-5\"\n",
    "  !git config core.sparsecheckout true\n",
    "  !echo -e \"scheduler\\ntext_encoder\\ntokenizer\\nunet\\nmodel_index.json\" > .git/info/sparse-checkout\n",
    "  !git pull origin main\n",
    "  if os.path.exists('/content/stable-diffusion-v1-5/unet/diffusion_pytorch_model.bin'):\n",
    "    !git clone \"https://USER:{token}@huggingface.co/stabilityai/sd-vae-ft-mse\"\n",
    "    !mv /content/stable-diffusion-v1-5/sd-vae-ft-mse /content/stable-diffusion-v1-5/vae\n",
    "    !rm -r /content/stable-diffusion-v1-5/.git\n",
    "    %cd /content/stable-diffusion-v1-5\n",
    "    !rm model_index.json\n",
    "    time.sleep(1)\n",
    "    wget.download('https://raw.githubusercontent.com/TheLastBen/fast-stable-diffusion/main/Dreambooth/model_index.json')\n",
    "    !sed -i 's@\"clip_sample\": false@@g' /content/stable-diffusion-v1-5/scheduler/scheduler_config.json\n",
    "    !sed -i 's@\"trained_betas\": null,@\"trained_betas\": null@g' /content/stable-diffusion-v1-5/scheduler/scheduler_config.json\n",
    "    !sed -i 's@\"sample_size\": 256,@\"sample_size\": 512,@g' /content/stable-diffusion-v1-5/vae/config.json\n",
    "    %cd /content/\n",
    "    clear_output()\n",
    "    print('\u001b[1;32mDONE !')\n",
    "  else:\n",
    "    while not os.path.exists('/content/stable-diffusion-v1-5/unet/diffusion_pytorch_model.bin'):\n",
    "         print('\u001b[1;31mMake sure you accepted the terms in https://huggingface.co/runwayml/stable-diffusion-v1-5')\n",
    "         time.sleep(5)\n",
    "\n",
    "\n",
    "def newdownloadmodel():\n",
    "\n",
    "  %cd /content/\n",
    "  clear_output()\n",
    "  !mkdir /content/stable-diffusion-v2-768\n",
    "  %cd /content/stable-diffusion-v2-768\n",
    "  !git init\n",
    "  !git lfs install --system --skip-repo\n",
    "  !git remote add -f origin  \"https://USER:{token}@huggingface.co/stabilityai/stable-diffusion-2\"\n",
    "  !git config core.sparsecheckout true\n",
    "  !echo -e \"scheduler\\ntext_encoder\\ntokenizer\\nunet\\nvae\\nmodel_index.json\" > .git/info/sparse-checkout\n",
    "  !git pull origin main\n",
    "  clear_output()\n",
    "  print('\u001b[1;32mDONE !')\n",
    "\n",
    "\n",
    "def newdownloadmodelb():\n",
    "\n",
    "  %cd /content/\n",
    "  clear_output()\n",
    "  !mkdir /content/stable-diffusion-v2-512\n",
    "  %cd /content/stable-diffusion-v2-512\n",
    "  !git init\n",
    "  !git lfs install --system --skip-repo\n",
    "  !git remote add -f origin  \"https://USER:{token}@huggingface.co/stabilityai/stable-diffusion-2-base\"\n",
    "  !git config core.sparsecheckout true\n",
    "  !echo -e \"scheduler\\ntext_encoder\\ntokenizer\\nunet\\nvae\\nmodel_index.json\" > .git/info/sparse-checkout\n",
    "  !git pull origin main\n",
    "  clear_output()\n",
    "  print('\u001b[1;32mDONE !')\n",
    "\n",
    "\n",
    "if Path_to_HuggingFace != \"\":\n",
    "  if V2_model:\n",
    "    if os.path.exists('/content/stable-diffusion-custom'):\n",
    "      !rm -r /content/stable-diffusion-custom\n",
    "    clear_output()\n",
    "    %cd /content/\n",
    "    clear_output()\n",
    "    !mkdir /content/stable-diffusion-custom\n",
    "    %cd /content/stable-diffusion-custom\n",
    "    !git init\n",
    "    !git lfs install --system --skip-repo\n",
    "    !git remote add -f origin  \"https://USER:{token}@huggingface.co/{Path_to_HuggingFace}\"\n",
    "    !git config core.sparsecheckout true\n",
    "    !echo -e \"scheduler\\ntext_encoder\\ntokenizer\\nunet\\nvae\\nmodel_index.json\" > .git/info/sparse-checkout\n",
    "    !git pull origin main\n",
    "    if os.path.exists('/content/stable-diffusion-custom/unet/diffusion_pytorch_model.bin'):\n",
    "      !rm -r /content/stable-diffusion-custom/.git\n",
    "      %cd /content/\n",
    "      MODEL_NAME=\"/content/stable-diffusion-custom\"\n",
    "      clear_output()\n",
    "      print('\u001b[1;32mDONE !')\n",
    "    else:\n",
    "      while not os.path.exists('/content/stable-diffusion-custom/unet/diffusion_pytorch_model.bin'):\n",
    "            print('\u001b[1;31mCheck the link you provided')\n",
    "            time.sleep(5)\n",
    "  else:\n",
    "    if os.path.exists('/content/stable-diffusion-custom'):\n",
    "      !rm -r /content/stable-diffusion-custom\n",
    "    clear_output()\n",
    "    %cd /content/\n",
    "    clear_output()\n",
    "    !mkdir /content/stable-diffusion-custom\n",
    "    %cd /content/stable-diffusion-custom\n",
    "    !git init\n",
    "    !git lfs install --system --skip-repo\n",
    "    !git remote add -f origin  \"https://USER:{token}@huggingface.co/{Path_to_HuggingFace}\"\n",
    "    !git config core.sparsecheckout true\n",
    "    !echo -e \"scheduler\\ntext_encoder\\ntokenizer\\nunet\\nmodel_index.json\" > .git/info/sparse-checkout\n",
    "    !git pull origin main\n",
    "    if os.path.exists('/content/stable-diffusion-custom/unet/diffusion_pytorch_model.bin'):\n",
    "      !git clone \"https://USER:{token}@huggingface.co/stabilityai/sd-vae-ft-mse\"\n",
    "      !mv /content/stable-diffusion-custom/sd-vae-ft-mse /content/stable-diffusion-custom/vae\n",
    "      !rm -r /content/stable-diffusion-custom/.git\n",
    "      %cd /content/stable-diffusion-custom\n",
    "      !rm model_index.json\n",
    "      time.sleep(1)\n",
    "      wget.download('https://raw.githubusercontent.com/TheLastBen/fast-stable-diffusion/main/Dreambooth/model_index.json')\n",
    "      !sed -i 's@\"clip_sample\": false@@g' /content/stable-diffusion-custom/scheduler/scheduler_config.json\n",
    "      !sed -i 's@\"trained_betas\": null,@\"trained_betas\": null@g' /content/stable-diffusion-custom/scheduler/scheduler_config.json\n",
    "      !sed -i 's@\"sample_size\": 256,@\"sample_size\": 512,@g' /content/stable-diffusion-custom/vae/config.json\n",
    "      %cd /content/\n",
    "      MODEL_NAME=\"/content/stable-diffusion-custom\"\n",
    "      clear_output()\n",
    "      print('\u001b[1;32mDONE !')\n",
    "    else:\n",
    "      while not os.path.exists('/content/stable-diffusion-custom/unet/diffusion_pytorch_model.bin'):\n",
    "            print('\u001b[1;31mCheck the link you provided')\n",
    "            time.sleep(5)\n",
    "\n",
    "\n",
    "elif CKPT_Path !=\"\":\n",
    "  if os.path.exists('/content/stable-custom'):\n",
    "    !rm -r /content/stable-diffusion-custom\n",
    "  if os.path.exists(str(CKPT_Path)):\n",
    "    !mkdir /content/stable-diffusion-custom\n",
    "    with capture.capture_output() as cap:\n",
    "      if Compatibility_Mode:\n",
    "        !wget https://raw.githubusercontent.com/huggingface/diffusers/039958eae55ff0700cfb42a7e72739575ab341f1/scripts/convert_original_stable_diffusion_to_diffusers.py\n",
    "        !python /content/convert_original_stable_diffusion_to_diffusers.py --checkpoint_path \"$CKPT_Path\" --dump_path /content/stable-diffusion-custom\n",
    "        !rm /content/convert_original_stable_diffusion_to_diffusers.py\n",
    "      else:\n",
    "        !python /content/diffusers/scripts/convert_original_stable_diffusion_to_diffusers.py --checkpoint_path \"$CKPT_Path\" --dump_path /content/stable-diffusion-custom\n",
    "    if os.path.exists('/content/stable-diffusion-custom/unet/diffusion_pytorch_model.bin'):\n",
    "      !rm /content/v1-inference.yaml\n",
    "      clear_output()\n",
    "      MODEL_NAME=\"/content/stable-diffusion-custom\"\n",
    "      print('\u001b[1;32mDONE !')\n",
    "    else:\n",
    "      !rm /content/convert_original_stable_diffusion_to_diffusers.py\n",
    "      !rm /content/v1-inference.yaml\n",
    "      !rm -r /content/stable-diffusion-custom\n",
    "      while not os.path.exists('/content/stable-diffusion-custom/unet/diffusion_pytorch_model.bin'):\n",
    "        print('\u001b[1;31mConversion error, Insufficient RAM or corrupt CKPT, use a 4GB CKPT instead of 7GB')\n",
    "        time.sleep(5)\n",
    "  else:\n",
    "    while not os.path.exists(str(CKPT_Path)):\n",
    "       print('\u001b[1;31mWrong path, use the colab file explorer to copy the path')\n",
    "       time.sleep(5)\n",
    "\n",
    "\n",
    "elif CKPT_Link !=\"\":\n",
    "    if os.path.exists('/content/stable-diffusion-custom'):\n",
    "      !rm -r /content/stable-diffusion-custom\n",
    "    !gdown --fuzzy -O model.ckpt $CKPT_Link\n",
    "    if os.path.exists('/content/model.ckpt'):\n",
    "      if os.path.getsize(\"/content/model.ckpt\") > 1810671599:\n",
    "        !mkdir /content/stable-diffusion-custom\n",
    "        with capture.capture_output() as cap:\n",
    "          if Compatibility_Mode:\n",
    "            !wget https://raw.githubusercontent.com/huggingface/diffusers/039958eae55ff0700cfb42a7e72739575ab341f1/scripts/convert_original_stable_diffusion_to_diffusers.py\n",
    "            !python /content/convert_original_stable_diffusion_to_diffusers.py --checkpoint_path /content/model.ckpt --dump_path /content/stable-diffusion-custom\n",
    "            !rm /content/convert_original_stable_diffusion_to_diffusers.py\n",
    "          else:\n",
    "            !python /content/diffusers/scripts/convert_original_stable_diffusion_to_diffusers.py --checkpoint_path /content/model.ckpt --dump_path /content/stable-diffusion-custom\n",
    "        if os.path.exists('/content/stable-diffusion-custom/unet/diffusion_pytorch_model.bin'):\n",
    "          clear_output()\n",
    "          MODEL_NAME=\"/content/stable-diffusion-custom\"\n",
    "          print('\u001b[1;32mDONE !')\n",
    "          !rm /content/v1-inference.yaml\n",
    "          !rm /content/model.ckpt\n",
    "        else:\n",
    "          if os.path.exists('/content/v1-inference.yaml'):\n",
    "            !rm /content/v1-inference.yaml\n",
    "          !rm /content/convert_original_stable_diffusion_to_diffusers.py\n",
    "          !rm -r /content/stable-diffusion-custom\n",
    "          !rm /content/model.ckpt\n",
    "          while not os.path.exists('/content/stable-diffusion-custom/unet/diffusion_pytorch_model.bin'):\n",
    "            print('\u001b[1;31mConversion error, Insufficient RAM or corrupt CKPT, use a 4GB CKPT instead of 7GB')\n",
    "            time.sleep(5)\n",
    "      else:\n",
    "        while os.path.getsize('/content/model.ckpt') < 1810671599:\n",
    "           print('\u001b[1;31mWrong link, check that the link is valid')\n",
    "           time.sleep(5)\n",
    "\n",
    "\n",
    "else:\n",
    "  if Model_Version==\"1.5\":\n",
    "    if not os.path.exists('/content/stable-diffusion-v1-5'):\n",
    "      downloadmodel()\n",
    "      MODEL_NAME=\"/content/stable-diffusion-v1-5\"\n",
    "    else:\n",
    "      MODEL_NAME=\"/content/stable-diffusion-v1-5\"\n",
    "      print(\"\u001b[1;32mThe v1.5 model already exists, using this model.\")\n",
    "  elif Model_Version==\"V2-512px\":\n",
    "    if not os.path.exists('/content/stable-diffusion-v2-512'):\n",
    "      newdownloadmodelb()\n",
    "      MODEL_NAME=\"/content/stable-diffusion-v2-512\"\n",
    "    else:\n",
    "      MODEL_NAME=\"/content/stable-diffusion-v2-512\"\n",
    "      print(\"\u001b[1;32mThe v2-512px model already exists, using this model.\")\n",
    "  elif Model_Version==\"V2-768px\":\n",
    "    if not os.path.exists('/content/stable-diffusion-v2-768'):\n",
    "      newdownloadmodel()\n",
    "      MODEL_NAME=\"/content/stable-diffusion-v2-768\"\n",
    "    else:\n",
    "      MODEL_NAME=\"/content/stable-diffusion-v2-768\"\n",
    "      print(\"\u001b[1;32mThe v2-768px model already exists, using this model.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wsp71Ctje5qg"
   },
   "source": [
    "### **Paso 4** - Configuramos el entrenamiento de Dreambooth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "executionInfo": {
     "elapsed": 65411,
     "status": "ok",
     "timestamp": 1673396318088,
     "user": {
      "displayName": "franciscopinelli",
      "userId": "17406683420579142537"
     },
     "user_tz": 180
    },
    "id": "1pH1oP-7yBZm",
    "outputId": "56d8b641-39ed-44ab-dcf0-9c7beaefb3d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;32mOK\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "from google.colab import files\n",
    "from IPython.display import clear_output\n",
    "from IPython.utils import capture\n",
    "#@markdown ---\n",
    "Training_Subject = \"Character\" #@param [\"Character\", \"Object\", \"Style\", \"Artist\", \"Movie\", \"TV Show\"]\n",
    "\n",
    "With_Prior_Preservation = \"Yes\" #@param [\"Yes\", \"No\"]\n",
    "#@markdown - With the prior reservation method, the results are better, you will either have to upload around 200 pictures of the class you're training (dog, person, car, house ...) or let Dreambooth generate them.\n",
    "\n",
    "MODEL_NAME=\"/content/stable-diffusion-v1-5\"\n",
    "\n",
    "Captionned_instance_images = False #@param {type:\"boolean\"}\n",
    "\n",
    "#@markdown - Use the keywords included in each instance images as unique instance prompt, this allows to train on multiple subjects at the same time, example :\n",
    "#@markdown - An instance image named fat_dog_doginstancename_in_a_pool.jpg\n",
    "#@markdown - another instance image named a_cat_catinstancename_in_the_woods.png\n",
    "#@markdown - the unique training instance prompts would be : fat dog doginstancename in a pool, a cat doginstancename in the woods\n",
    "#@markdown - at inference you can generate the dog by simply using doginstancename (a random unique identifier) or the cat by catinstancename\n",
    "\n",
    "#@markdown - Also you can enhance the training of a simple subject by simply describing the image using keywords like : smiling, outdoor, sad, lether jacket ...etc\n",
    "\n",
    "#@markdown - If you enable this feature, and want to train on multiple subjects, use the AUTOMATIC1111 colab to generate good quality 512x512 100-200 Class images for each subject (dog and a cat and a cow), then put them all in the same folder and entrer the folder's path in the cell below.\n",
    "\n",
    "#@markdown - If you enable this feature, you must add an instance name and a subject type (dog, man, car) to all the images, separate keywords by an underscore (_).\n",
    "\n",
    "\n",
    "\n",
    "SUBJECT_TYPE = \"person\" #@param{type: 'string'}\n",
    "while SUBJECT_TYPE==\"\":\n",
    "   SUBJECT_TYPE=input('Input the subject type:')\n",
    "\n",
    "#@markdown - If you're training on a character or an object, the subject type would be : Man, Woman, Shirt, Car, Dog, Baby ...etc\n",
    "#@markdown - If you're training on a Style, the subject type would be : impressionist, brutalist, abstract, use \"beautiful\" for a general style...etc\n",
    "#@markdown - If you're training on a Movie/Show, the subject type would be : Action, Drama, Science-fiction, Comedy ...etc\n",
    "#@markdown - If you're training on an Artist, the subject type would be : Painting, sketch, drawing, photography, art ...etc\n",
    "\n",
    "\n",
    "INSTANCE_NAME= \"Juan_Francisco_Pinelli_Bernard\" #@param{type: 'string'} That's me!\n",
    "while INSTANCE_NAME==\"\":\n",
    "   INSTANCE_NAME=input('Input the instance name (identifier) :')\n",
    "\n",
    "#@markdown - The instance is an identifier, choose a unique identifier unknown by stable diffusion.\n",
    "\n",
    "INSTANCE_DIR_OPTIONAL=\"\" #@param{type: 'string'}\n",
    "INSTANCE_DIR=INSTANCE_DIR_OPTIONAL\n",
    "while INSTANCE_DIR_OPTIONAL!=\"\" and not os.path.exists(str(INSTANCE_DIR)):\n",
    "    INSTANCE_DIR=input('\u001b[1;31mThe instance folder specified does not exist, use the colab file explorer to copy the path :')\n",
    "\n",
    "#@markdown - If the number of instance pictures is large, it is preferable to specify directly the folder instead of uploading, leave EMPTY to upload.\n",
    "\n",
    "CLASS_DIR=\"/content/data/\"+ SUBJECT_TYPE\n",
    "Number_of_subject_images=500#@param{type: 'number'}\n",
    "while Number_of_subject_images==None:\n",
    "     Number_of_subject_images=input('Input the number of subject images :')\n",
    "SUBJECT_IMAGES=Number_of_subject_images\n",
    "\n",
    "Save_class_images_to_gdrive = False #@param {type:\"boolean\"}\n",
    "#@markdown - Save time in case you're training multiple instances of the same class\n",
    "\n",
    "if Training_Subject==\"Character\" or Training_Subject==\"Object\":\n",
    "  PT=\"photo of \"+INSTANCE_NAME+\" \"+SUBJECT_TYPE\n",
    "  CPT=\"a photo of a \"+SUBJECT_TYPE+\", ultra detailed\"\n",
    "  if Captionned_instance_images:\n",
    "    PT=\"photo of\"\n",
    "elif Training_Subject==\"Style\":\n",
    "  With_Prior_Preservation = \"No\"\n",
    "  PT=\"in the \"+SUBJECT_TYPE+\" style of \"+INSTANCE_NAME\n",
    "  if Captionned_instance_images:\n",
    "    PT=\"in the style of\"\n",
    "elif Training_Subject==\"Artist\":\n",
    "  With_Prior_Preservation = \"No\"\n",
    "  PT=SUBJECT_TYPE+\" By \"+INSTANCE_NAME\n",
    "  if Captionned_instance_images:\n",
    "    PT=\"by the artist\"\n",
    "elif Training_Subject==\"Movie\":\n",
    "  PT=\"from the \"+SUBJECT_TYPE+\" movie \"+ INSTANCE_NAME\n",
    "  CPT=\"still frame from \"+SUBJECT_TYPE+\" movie, ultra detailed, 4k uhd\"\n",
    "  if Captionned_instance_images:\n",
    "    PT=\"from the movie\"\n",
    "elif Training_Subject==\"TV Show\":\n",
    "  CPT=\"still frame from \"+SUBJECT_TYPE+\" tv show, ultra detailed, 4k uhd\"\n",
    "  PT=\"from the \"+SUBJECT_TYPE+\" tv show \"+ INSTANCE_NAME\n",
    "  if Captionned_instance_images:\n",
    "    PT=\"from the tv show\"\n",
    "\n",
    "OUTPUT_DIR=\"/content/models/\"+ INSTANCE_NAME\n",
    "\n",
    "if INSTANCE_DIR_OPTIONAL==\"\":\n",
    "  INSTANCE_DIR=\"/content/data/\"+INSTANCE_NAME\n",
    "  !mkdir -p \"$INSTANCE_DIR\"\n",
    "  uploaded = files.upload()\n",
    "  for filename in uploaded.keys():\n",
    "    shutil.move(filename, INSTANCE_DIR)\n",
    "    clear_output()\n",
    "\n",
    "with capture.capture_output() as cap:\n",
    "   %cd \"$INSTANCE_DIR\"\n",
    "   !find . -name \"* *\" -type f | rename 's/ /_/g'\n",
    "   %cd /content\n",
    "print('\u001b[1;32mOK')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rYmyuQctfATh"
   },
   "source": [
    "### **Paso 5** - (Opcional) Descargamos imágenes de regularización.  💖 Gracias [Joe Penna](https://github.com/JoePenna/Dreambooth-Stable-Diffusion)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1481,
     "status": "ok",
     "timestamp": 1673396569437,
     "user": {
      "displayName": "franciscopinelli",
      "userId": "17406683420579142537"
     },
     "user_tz": 180
    },
    "id": "ze4P8wWPjy7F",
    "outputId": "4658d011-b30a-47f8-c449-ef317c2d2d96"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'Stable-Diffusion-Regularization-Images-person_ddim' already exists and is not an empty directory.\n",
      "mv: cannot stat 'Stable-Diffusion-Regularization-Images-person_ddim/person_ddim/*.*': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "#@markdown We’ve created the following image sets\n",
    "#@markdown - `man_euler` - provided by Niko Pueringer (Corridor Digital) - euler @ 40 steps, CFG 7.5\n",
    "#@markdown - `man_unsplash` - pictures from various photographers\n",
    "#@markdown - `person_ddim`\n",
    "#@markdown - `woman_ddim` - provided by David Bielejeski - ddim @ 50 steps, CFG 10.0 <br />\n",
    "#@markdown - `blonde_woman` - provided by David Bielejeski - ddim @ 50 steps, CFG 10.0 <br />\n",
    "\n",
    "dataset=\"person_ddim\" #@param [\"man_euler\", \"man_unsplash\", \"person_ddim\", \"woman_ddim\", \"blonde_woman\"]\n",
    "!git clone https://github.com/djbielejeski/Stable-Diffusion-Regularization-Images-{dataset}.git\n",
    "\n",
    "!mkdir -p regularization_images/{dataset}\n",
    "!mv -v Stable-Diffusion-Regularization-Images-{dataset}/{dataset}/*.* regularization_images/{dataset}\n",
    "CLASS_DIR=\"/content/regularization_images/\" + dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OmIz45s0gH5c"
   },
   "source": [
    "### **Paso 6** - ...y ahora **¡A ENTRENAR!** 💪"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1673391708593,
     "user": {
      "displayName": "franciscopinelli",
      "userId": "17406683420579142537"
     },
     "user_tz": 180
    },
    "id": "17x2DlOVDxAs",
    "outputId": "67ba05b0-207e-4e91-b66b-782dc0bbc33a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2021 NVIDIA Corporation\n",
      "Built on Sun_Feb_14_21:12:58_PST_2021\n",
      "Cuda compilation tools, release 11.2, V11.2.152\n",
      "Build cuda_11.2.r11.2/compiler.29618528_0\n"
     ]
    }
   ],
   "source": [
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8110,
     "status": "ok",
     "timestamp": 1673391734902,
     "user": {
      "displayName": "franciscopinelli",
      "userId": "17406683420579142537"
     },
     "user_tz": 180
    },
    "id": "-7eAt2EZCHuF",
    "outputId": "e2bdeaa7-99c5-4d91-e743-92e41450dba9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.8/dist-packages (4.25.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.13.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.11.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (4.0.0)\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.8/dist-packages (0.36.0.post2)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip install bitsandbytes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 51873,
     "status": "ok",
     "timestamp": 1673391865203,
     "user": {
      "displayName": "franciscopinelli",
      "userId": "17406683420579142537"
     },
     "user_tz": 180
    },
    "id": "1-9QbkfAVYYU",
    "outputId": "1fb19924-8ae4-4704-922f-9da24ec49750"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
      "\t`--num_processes` was set to a value of `1`\n",
      "\t`--num_machines` was set to a value of `1`\n",
      "\t`--mixed_precision` was set to a value of `'no'`\n",
      "\t`--num_cpu_threads_per_process` was set to `1` to improve out-of-box performance\n",
      "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please submit your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "For effortless bug reporting copy-paste your error into this form: https://docs.google.com/forms/d/e/1FAIpQLScPB8emS3Thkp66nvqwmjTEgxp8Y9ufuWTzFyr9kJ5AoI47dQ/viewform?usp=sf_link\n",
      "================================================================================\n",
      "/usr/local/lib/python3.8/dist-packages/bitsandbytes/cuda_setup/main.py:134: UserWarning: /usr/lib64-nvidia did not contain libcudart.so as expected! Searching further paths...\n",
      "  warn(msg)\n",
      "/usr/local/lib/python3.8/dist-packages/bitsandbytes/cuda_setup/main.py:134: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('--listen_host=172.28.0.12 --target_host=172.28.0.12 --tunnel_background_save_url=https'), PosixPath('//colab.research.google.com/tun/m/cc48301118ce562b961b3c22d803539adc1e0c19/gpu-t4-s-2aw74vwlcwonr --tunnel_background_save_delay=10s --tunnel_periodic_background_save_frequency=30m0s --enable_output_coalescing=true --output_coalescing_required=true')}\n",
      "  warn(msg)\n",
      "/usr/local/lib/python3.8/dist-packages/bitsandbytes/cuda_setup/main.py:134: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('true}'), PosixPath('[\"--ip=172.28.0.12\",\"--transport=ipc\"],\"debugAdapterMultiplexerPath\"'), PosixPath('6000,\"kernelManagerProxyHost\"'), PosixPath('{\"kernelManagerProxyPort\"'), PosixPath('\"172.28.0.12\",\"jupyterArgs\"'), PosixPath('\"/usr/local/bin/dap_multiplexer\",\"enableLsp\"')}\n",
      "  warn(msg)\n",
      "/usr/local/lib/python3.8/dist-packages/bitsandbytes/cuda_setup/main.py:134: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('//ipykernel.pylab.backend_inline'), PosixPath('module')}\n",
      "  warn(msg)\n",
      "/usr/local/lib/python3.8/dist-packages/bitsandbytes/cuda_setup/main.py:134: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/env/python')}\n",
      "  warn(msg)\n",
      "/usr/local/lib/python3.8/dist-packages/bitsandbytes/cuda_setup/main.py:134: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/sys/fs/cgroup/memory.events /var/colab/cgroup/jupyter-children/memory.events')}\n",
      "  warn(msg)\n",
      "CUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching /usr/local/cuda/lib64...\n",
      "CUDA SETUP: CUDA runtime path found: /usr/local/cuda/lib64/libcudart.so\n",
      "CUDA SETUP: Highest compute capability among GPUs detected: 7.5\n",
      "CUDA SETUP: Detected CUDA version 112\n",
      "CUDA SETUP: Loading binary /usr/local/lib/python3.8/dist-packages/bitsandbytes/libbitsandbytes_cuda112.so...\n",
      "Progress:|                         |:   0% 1/1600 [00:08<3:47:46,  8.55s/it, loss=0.576, lr=1e-6]Traceback (most recent call last):\n",
      "  File \"/content/diffusers/examples/dreambooth/train_dreambooth.py\", line 852, in <module>\n",
      "    main()\n",
      "  File \"/content/diffusers/examples/dreambooth/train_dreambooth.py\", line 719, in main\n",
      "    accelerator.backward(loss)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/accelerate/accelerator.py\", line 882, in backward\n",
      "    self.scaler.scale(loss).backward(**kwargs)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/_tensor.py\", line 487, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/__init__.py\", line 197, in backward\n",
      "    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/function.py\", line 267, in apply\n",
      "    return user_fn(self, *args)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/utils/checkpoint.py\", line 157, in backward\n",
      "    torch.autograd.backward(outputs_with_grad, args_with_grad)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/__init__.py\", line 197, in backward\n",
      "    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 1024.00 MiB (GPU 0; 14.76 GiB total capacity; 11.39 GiB already allocated; 253.75 MiB free; 13.22 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
      "Progress:|                         |:   0% 1/1600 [00:09<4:12:27,  9.47s/it, loss=0.576, lr=1e-6]\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/bin/accelerate\", line 8, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/accelerate/commands/accelerate_cli.py\", line 43, in main\n",
      "    args.func(args)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/accelerate/commands/launch.py\", line 837, in launch_command\n",
      "    simple_launcher(args)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/accelerate/commands/launch.py\", line 354, in simple_launcher\n",
      "    raise subprocess.CalledProcessError(returncode=process.returncode, cmd=cmd)\n",
      "subprocess.CalledProcessError: Command '['/usr/bin/python3', '/content/diffusers/examples/dreambooth/train_dreambooth.py', '--save_starting_step=500', '--save_n_steps=0', '--train_text_encoder', '--pretrained_model_name_or_path=/content/stable-diffusion-v1-5', '--instance_data_dir=/content/data/Juan_Francisco_Pinelli_Bernard', '--class_data_dir=/content/regularization_images/person_ddim', '--output_dir=/content/models/Juan_Francisco_Pinelli_Bernard', '--with_prior_preservation', '--prior_loss_weight=1.0', '--instance_prompt=photo of Juan_Francisco_Pinelli_Bernard person', '--class_prompt=a photo of a person, ultra detailed', '--seed=75576', '--resolution=512', '--mixed_precision=fp16', '--train_batch_size=1', '--gradient_accumulation_steps=1', '--gradient_checkpointing', '--use_8bit_adam', '--learning_rate=1e-6', '--lr_scheduler=constant', '--lr_warmup_steps=0', '--center_crop', '--max_train_steps=1600', '--num_class_images=500']' returned non-zero exit status 1.\n",
      "\u001b[1;31mSomething went wrong\n"
     ]
    }
   ],
   "source": [
    "#@markdown ---\n",
    "import os\n",
    "from subprocess import getoutput\n",
    "from IPython.display import HTML\n",
    "\n",
    "fp16 = True #@param {type:\"boolean\"}\n",
    "if fp16:\n",
    "  prec=\"fp16\"\n",
    "else:\n",
    "  prec=\"no\"\n",
    "\n",
    "#@markdown  - fp16 or half precision meaning slightly lower quality but double the speed.\n",
    "s = getoutput('nvidia-smi')\n",
    "if 'A100' in s:\n",
    "  precision=\"no\"\n",
    "else:\n",
    "  precision=prec\n",
    "\n",
    "Training_Steps=\"1600\" #@param{type: 'string'}\n",
    "#@markdown - Keep it around 1600 to avoid overtraining.\n",
    "\n",
    "Seed=75576 #@param{type: 'number'}\n",
    "\n",
    "#@markdown ---------------------------\n",
    "Save_Checkpoint_Every_n_Steps = False #@param {type:\"boolean\"}\n",
    "Save_Checkpoint_Every=500 #@param{type: 'number'}\n",
    "if Save_Checkpoint_Every==None:\n",
    "  Save_Checkpoint_Every=1\n",
    "#@markdown - Minimum 200 steps between each save.\n",
    "stp=0\n",
    "Start_saving_from_the_step=500 #@param{type: 'number'}\n",
    "if Start_saving_from_the_step==None:\n",
    "  Start_saving_from_the_step=0\n",
    "if (Start_saving_from_the_step < 200):\n",
    "  Start_saving_from_the_step=Save_Checkpoint_Every\n",
    "stpsv=Start_saving_from_the_step\n",
    "if Save_Checkpoint_Every_n_Steps:\n",
    "  stp=Save_Checkpoint_Every\n",
    "#@markdown - Start saving intermediary checkpoints from this step.\n",
    "\n",
    "Caption=''\n",
    "if Captionned_instance_images:\n",
    "  Caption='--image_captions_filename'\n",
    "\n",
    "if With_Prior_Preservation=='No':\n",
    "  !accelerate launch /content/diffusers/examples/dreambooth/train_dreambooth.py \\\n",
    "    $Caption \\\n",
    "    --save_starting_step=$stpsv \\\n",
    "    --save_n_steps=$stp \\\n",
    "    --train_text_encoder \\\n",
    "    --pretrained_model_name_or_path=\"$MODEL_NAME\" \\\n",
    "    --instance_data_dir=\"$INSTANCE_DIR\" \\\n",
    "    --output_dir=\"$OUTPUT_DIR\" \\\n",
    "    --instance_prompt=\"$PT\" \\\n",
    "    --seed=$Seed \\\n",
    "    --resolution=512 \\\n",
    "    --mixed_precision=$precision \\\n",
    "    --train_batch_size=1 \\\n",
    "    --gradient_accumulation_steps=1 \\\n",
    "    --use_8bit_adam \\\n",
    "    --learning_rate=1e-6 \\\n",
    "    --lr_scheduler=\"constant\" \\\n",
    "    --center_crop \\\n",
    "    --lr_warmup_steps=0 \\\n",
    "    --max_train_steps=$Training_Steps\n",
    "\n",
    "else:\n",
    "\n",
    "  !accelerate launch /content/diffusers/examples/dreambooth/train_dreambooth.py \\\n",
    "    $Caption \\\n",
    "    --save_starting_step=$stpsv \\\n",
    "    --save_n_steps=$stp \\\n",
    "    --train_text_encoder \\\n",
    "    --pretrained_model_name_or_path=\"$MODEL_NAME\" \\\n",
    "    --instance_data_dir=\"$INSTANCE_DIR\" \\\n",
    "    --class_data_dir=\"$CLASS_DIR\" \\\n",
    "    --output_dir=\"$OUTPUT_DIR\" \\\n",
    "    --with_prior_preservation --prior_loss_weight=1.0 \\\n",
    "    --instance_prompt=\"$PT\"\\\n",
    "    --class_prompt=\"$CPT\" \\\n",
    "    --seed=$Seed \\\n",
    "    --resolution=512 \\\n",
    "    --mixed_precision=$precision \\\n",
    "    --train_batch_size=1 \\\n",
    "    --gradient_accumulation_steps=1 --gradient_checkpointing \\\n",
    "    --use_8bit_adam \\\n",
    "    --learning_rate=1e-6 \\\n",
    "    --lr_scheduler=\"constant\" \\\n",
    "    --lr_warmup_steps=0 \\\n",
    "    --center_crop \\\n",
    "    --max_train_steps=$Training_Steps \\\n",
    "    --num_class_images=$SUBJECT_IMAGES\n",
    "\n",
    "if Save_class_images_to_gdrive:\n",
    "  if os.path.exists(str(CLASS_DIR)):\n",
    "    if not os.path.exists('/content/gdrive/MyDrive/Class_images'):\n",
    "      !mkdir /content/gdrive/MyDrive/Class_images\n",
    "    Class_gdir= '/content/gdrive/MyDrive/Class_images/'+SUBJECT_TYPE\n",
    "    if not os.path.exists(str(Class_gdir)):\n",
    "      !cp -r \"$CLASS_DIR\" /content/gdrive/MyDrive/Class_images\n",
    "\n",
    "if os.path.exists('/content/models/'+INSTANCE_NAME+'/unet/diffusion_pytorch_model.bin'):\n",
    "  print(\"Almost done ...\")\n",
    "  %cd /content\n",
    "  !wget -O convertosd.py https://github.com/TheLastBen/fast-stable-diffusion/raw/main/Dreambooth/convertosd.py\n",
    "  clear_output()\n",
    "  if precision==\"no\":\n",
    "    !sed -i '226s@.*@@' /content/convertosd.py\n",
    "  !sed -i '201s@.*@    model_path = \"{OUTPUT_DIR}\"@' /content/convertosd.py\n",
    "  !sed -i '202s@.*@    checkpoint_path= \"/content/gdrive/MyDrive/{INSTANCE_NAME}.ckpt\"@' /content/convertosd.py\n",
    "  !python /content/convertosd.py\n",
    "  clear_output()\n",
    "  if os.path.exists('/content/gdrive/MyDrive/'+INSTANCE_NAME+'.ckpt'):\n",
    "    print(\"\u001b[1;32mDONE, the CKPT model is in your Gdrive\")\n",
    "  else:\n",
    "    print(\"\u001b[1;31mSomething went wrong\")\n",
    "else:\n",
    "  print(\"\u001b[1;31mSomething went wrong\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qbclw_Gmg3DC"
   },
   "source": [
    "### **Paso 7** (Opcional) - **Prueba el modelo**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iAZGngFcI8hq"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import sys\n",
    "import fileinput\n",
    "from IPython.display import clear_output\n",
    "from subprocess import getoutput\n",
    "from IPython.utils import capture\n",
    "\n",
    "\n",
    "Model_Version = \"1.5\"\n",
    "\n",
    "Update_repo = True #@param {type:\"boolean\"}\n",
    "\n",
    "Session__Name=\"\" #@param{type: 'string'}\n",
    "\n",
    "#@markdown - Leave empty if you want to use the current trained model.\n",
    "\n",
    "Use_Custom_Path = False #@param {type:\"boolean\"}\n",
    "\n",
    "try:\n",
    "  INSTANCE_NAME\n",
    "  INSTANCET=INSTANCE_NAME\n",
    "except:\n",
    "  pass\n",
    "#@markdown - if checked, an input box will ask the full path to a desired model.\n",
    "\n",
    "if Session__Name!=\"\":\n",
    "  INSTANCET=Session__Name\n",
    "  INSTANCET=INSTANCET.replace(\" \",\"_\")\n",
    "\n",
    "if Use_Custom_Path:\n",
    "  try:\n",
    "    INSTANCET\n",
    "    del INSTANCET\n",
    "  except:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "  INSTANCET\n",
    "  if Session__Name!=\"\":\n",
    "    path_to_trained_model='/content/gdrive/MyDrive/Fast-Dreambooth/Sessions/'+Session__Name+\"/\"+Session__Name+'.ckpt'\n",
    "  else:\n",
    "    path_to_trained_model='/content/gdrive/MyDrive/'+INSTANCET+'.ckpt'\n",
    "except:\n",
    "  print('\u001b[1;31mIt seems that you did not perform training during this session \u001b[1;32mor you chose to use a custom path,\\nprovide the full path to the model (including the name of the model):\\n')\n",
    "  path_to_trained_model=input()\n",
    "\n",
    "while not os.path.exists(path_to_trained_model):\n",
    "   print(\"\u001b[1;31mThe model doesn't exist on you Gdrive, use the file explorer to get the path : \")\n",
    "   path_to_trained_model=input()\n",
    "\n",
    "\n",
    "with capture.capture_output() as cap:\n",
    "    %cd /content/gdrive/MyDrive/\n",
    "    %mkdir sd\n",
    "    %cd sd\n",
    "    !git clone https://github.com/Stability-AI/stablediffusion\n",
    "    !git clone https://github.com/AUTOMATIC1111/stable-diffusion-webui\n",
    "    %cd /content/gdrive/MyDrive/sd/stable-diffusion-webui/\n",
    "    !mkdir -p cache/{huggingface,torch}\n",
    "    %cd /content/\n",
    "    !ln -s /content/gdrive/MyDrive/sd/stable-diffusion-webui/cache/huggingface ../root/.cache/\n",
    "    !ln -s /content/gdrive/MyDrive/sd/stable-diffusion-webui/cache/torch ../root/.cache/\n",
    "\n",
    "if Update_repo:\n",
    "  !rm /content/gdrive/MyDrive/sd/stable-diffusion-webui/webui.sh\n",
    "  !rm /content/gdrive/MyDrive/sd/stable-diffusion-webui/modules/paths.py\n",
    "  !rm /content/gdrive/MyDrive/sd/stable-diffusion-webui/webui.py\n",
    "  !rm /content/gdrive/MyDrive/sd/stable-diffusion-webui/modules/ui.py\n",
    "  !rm /content/gdrive/MyDrive/sd/stable-diffusion-webui/style.css\n",
    "  %cd /content/gdrive/MyDrive/sd/stable-diffusion-webui/\n",
    "  clear_output()\n",
    "  print('\u001b[1;32m')\n",
    "  !git pull\n",
    "\n",
    "\n",
    "with capture.capture_output() as cap:\n",
    "\n",
    "  if not os.path.exists('/content/gdrive/MyDrive/sd/stablediffusion/src/k-diffusion/k_diffusion'):\n",
    "    !mkdir /content/gdrive/MyDrive/sd/stablediffusion/src\n",
    "    %cd /content/gdrive/MyDrive/sd/stablediffusion/src\n",
    "    !git clone https://github.com/CompVis/taming-transformers\n",
    "    !git clone https://github.com/openai/CLIP\n",
    "    !git clone https://github.com/salesforce/BLIP\n",
    "    !git clone https://github.com/sczhou/CodeFormer\n",
    "    !git clone https://github.com/crowsonkb/k-diffusion\n",
    "    !mv /content/gdrive/MyDrive/sd/stablediffusion/src/CLIP /content/gdrive/MyDrive/sd/stablediffusion/src/clip\n",
    "    !mv  /content/gdrive/MyDrive/sd/stablediffusion/src/BLIP /content/gdrive/MyDrive/sd/stablediffusion/src/blip\n",
    "    !mv  /content/gdrive/MyDrive/sd/stablediffusion/src/CodeFormer /content/gdrive/MyDrive/sd/stablediffusion/src/codeformer\n",
    "    !cp -r /content/gdrive/MyDrive/sd/stablediffusion/src/k-diffusion/k_diffusion /content/gdrive/MyDrive/sd/stable-diffusion-webui/\n",
    "\n",
    "\n",
    "with capture.capture_output() as cap:\n",
    "  %cd /content/gdrive/MyDrive/sd/stable-diffusion-webui/modules\n",
    "  !wget -O paths.py https://raw.githubusercontent.com/TheLastBen/fast-stable-diffusion/main/AUTOMATIC1111_files/paths.py\n",
    "\n",
    "with capture.capture_output() as cap:\n",
    "  if not os.path.exists('/tools/node/bin/lt'):\n",
    "    !npm install -g localtunnel\n",
    "\n",
    "with capture.capture_output() as cap:\n",
    "  %cd /content/gdrive/MyDrive/sd/stable-diffusion-webui/\n",
    "  time.sleep(1)\n",
    "  !wget -O webui.py https://raw.githubusercontent.com/AUTOMATIC1111/stable-diffusion-webui/master/webui.py\n",
    "  !sed -i 's@gpu_call).*@gpu_call) \\n        shared.demo.queue(concurrency_count=111500)@' /content/gdrive/MyDrive/sd/stable-diffusion-webui/webui.py\n",
    "  %cd /content/gdrive/MyDrive/sd/stable-diffusion-webui/modules/\n",
    "  !wget -O ui.py https://raw.githubusercontent.com/AUTOMATIC1111/stable-diffusion-webui/master/modules/ui.py\n",
    "  !sed -i 's@css = \"\".*@with open(os.path.join(script_path, \"style.css\"), \"r\", encoding=\"utf8\") as file:\\n        css = file.read()@' /content/gdrive/MyDrive/sd/stable-diffusion-webui/modules/ui.py\n",
    "  %cd /content/gdrive/MyDrive/sd/stable-diffusion-webui\n",
    "  !wget -O style.css https://raw.githubusercontent.com/AUTOMATIC1111/stable-diffusion-webui/master/style.css\n",
    "  !sed -i 's@min-height: 4.*@min-height: 5.5em;@g' /content/gdrive/MyDrive/sd/stable-diffusion-webui/style.css\n",
    "  %cd /content\n",
    "\n",
    "\n",
    "Use_Gradio_Server = False #@param {type:\"boolean\"}\n",
    "#@markdown  - Only if you have trouble connecting to the local server.\n",
    "\n",
    "\n",
    "share=''\n",
    "if Use_Gradio_Server:\n",
    "  share='--share'\n",
    "  for line in fileinput.input('/usr/local/lib/python3.8/dist-packages/gradio/blocks.py', inplace=True):\n",
    "    if line.strip().startswith('self.server_name ='):\n",
    "        line = '            self.server_name = server_name\\n'\n",
    "    if line.strip().startswith('self.server_port ='):\n",
    "        line = '            self.server_port = server_port\\n'\n",
    "    sys.stdout.write(line)\n",
    "  clear_output()\n",
    "\n",
    "else:\n",
    "  share=''\n",
    "  !nohup lt --port 7860 > srv.txt 2>&1 &\n",
    "  time.sleep(2)\n",
    "  !grep -o 'https[^ ]*' /content/srv.txt >srvr.txt\n",
    "  time.sleep(2)\n",
    "  srv= getoutput('cat /content/srvr.txt')\n",
    "\n",
    "  for line in fileinput.input('/usr/local/lib/python3.8/dist-packages/gradio/blocks.py', inplace=True):\n",
    "    if line.strip().startswith('self.server_name ='):\n",
    "        line = f'            self.server_name = \"{srv[8:]}\"\\n'\n",
    "    if line.strip().startswith('self.server_port ='):\n",
    "        line = '            self.server_port = 443\\n'\n",
    "    if line.strip().startswith('self.protocol = \"https\"'):\n",
    "        line = '            self.protocol = \"https\"\\n'\n",
    "    if line.strip().startswith('if self.local_url.startswith(\"https\") or self.is_colab'):\n",
    "        line = ''\n",
    "    if line.strip().startswith('else \"http\"'):\n",
    "        line = ''\n",
    "    sys.stdout.write(line)\n",
    "\n",
    "\n",
    "  !sed -i '13s@.*@    \"PUBLIC_SHARE_TRUE\": \"\u001b[32mConnected\",@' /usr/local/lib/python3.8/dist-packages/gradio/strings.py\n",
    "\n",
    "  !rm /content/srv.txt\n",
    "  !rm /content/srvr.txt\n",
    "  clear_output()\n",
    "\n",
    "with capture.capture_output() as cap:\n",
    "  %cd /content/gdrive/MyDrive/sd/stablediffusion/\n",
    "\n",
    "if Model_Version == \"V2-768\":\n",
    "  configf=\"--config /content/gdrive/MyDrive/sd/stablediffusion/configs/stable-diffusion/v2-inference-v.yaml\"\n",
    "  NM=\"True\"\n",
    "elif Model_Version == \"V2-512\":\n",
    "  configf=\"--config /content/gdrive/MyDrive/sd/stablediffusion/configs/stable-diffusion/v2-inference.yaml\"\n",
    "  NM=\"True\"\n",
    "else:\n",
    "  configf=\"\"\n",
    "  NM=\"False\"\n",
    "\n",
    "if os.path.exists('/usr/local/lib/python3.8/dist-packages/xformers'):\n",
    "  xformers=\"--xformers\"\n",
    "else:\n",
    "  xformers=\"\"\n",
    "\n",
    "if os.path.isfile(path_to_trained_model):\n",
    "  !python /content/gdrive/MyDrive/sd/stable-diffusion-webui/webui.py $share --disable-safe-unpickle --no-half-vae  --ckpt \"$path_to_trained_model\" $configf $xformers\n",
    "else:\n",
    "  !python /content/gdrive/MyDrive/sd/stable-diffusion-webui/webui.py $share --disable-safe-unpickle --no-half-vae  --ckpt-dir \"$path_to_trained_model\" $configf $xformers"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "WCgtpGr6ZOyG",
    "CnBAZ4eje2Sl",
    "Wsp71Ctje5qg",
    "rYmyuQctfATh",
    "OmIz45s0gH5c",
    "Qbclw_Gmg3DC"
   ],
   "provenance": [
    {
     "file_id": "19ZqzHRdwht6dS634LrtSE-F7CFbgzCd4",
     "timestamp": 1673325603171
    },
    {
     "file_id": "1-HIbslQd7Ei_mAt25ipqSUMvbe3POm98",
     "timestamp": 1673324313428
    },
    {
     "file_id": "1MN2We5kgqYSOZ317KQcCbsNLgasncBQ1",
     "timestamp": 1666783236646
    },
    {
     "file_id": "https://github.com/TheLastBen/fast-stable-diffusion/blob/main/fast-DreamBooth.ipynb",
     "timestamp": 1666688632136
    }
   ]
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
