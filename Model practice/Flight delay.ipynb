{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28c60753",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "152555d37b8649b698187950fb7f0483",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "                                             |                                             | [  0%]   00:00 ->…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report my_report.html was generated! NOTEBOOK/COLAB USERS: the web browser MAY not pop up, regardless, the report IS saved in your notebook/colab files.\n"
     ]
    }
   ],
   "source": [
    "import sweetviz as sv\n",
    "import pandas as pd\n",
    "\n",
    "# Cargo los datos\n",
    "df = pd.read_csv('FlightDelays_Data_3.0.csv')\n",
    "\n",
    "report = sv.analyze(df.dropna(subset=['Canceled']),target_feat='Canceled')\n",
    "report.show_html('my_report.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f616fade",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores hiperparámetros para BaggingClassifier: {'n_estimators': 10}\n",
      "Mejor score para BaggingClassifier: 0.9958298582151792\n",
      "Mejores hiperparámetros para DecisionTreeClassifier: {'max_depth': 5}\n",
      "Mejor score para DecisionTreeClassifier: 0.9956630525437864\n",
      "Mejores hiperparámetros para HistGradientBoostingClassifier: {'learning_rate': 0.01, 'max_depth': 3}\n",
      "Mejor score para HistGradientBoostingClassifier: 0.9963302752293577\n",
      "Mejores hiperparámetros para RandomForestClassifier: {'n_estimators': 50}\n",
      "Mejor score para RandomForestClassifier: 0.9963302752293577\n",
      "Mejores hiperparámetros para StackingClassifier: {}\n",
      "Mejor score para StackingClassifier: 0.9961634695579649\n",
      "[LightGBM] [Info] Number of positive: 799, number of negative: 3997\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000319 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1085\n",
      "[LightGBM] [Info] Number of data points in the train set: 4796, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.166597 -> initscore=-1.609938\n",
      "[LightGBM] [Info] Start training from score -1.609938\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 799, number of negative: 3997\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000128 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1085\n",
      "[LightGBM] [Info] Number of data points in the train set: 4796, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.166597 -> initscore=-1.609938\n",
      "[LightGBM] [Info] Start training from score -1.609938\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 799, number of negative: 3997\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000152 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1089\n",
      "[LightGBM] [Info] Number of data points in the train set: 4796, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.166597 -> initscore=-1.609938\n",
      "[LightGBM] [Info] Start training from score -1.609938\n",
      "[LightGBM] [Info] Number of positive: 799, number of negative: 3997\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000166 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1085\n",
      "[LightGBM] [Info] Number of data points in the train set: 4796, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.166597 -> initscore=-1.609938\n",
      "[LightGBM] [Info] Start training from score -1.609938\n",
      "[LightGBM] [Info] Number of positive: 800, number of negative: 3996\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000155 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1074\n",
      "[LightGBM] [Info] Number of data points in the train set: 4796, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.166806 -> initscore=-1.608437\n",
      "[LightGBM] [Info] Start training from score -1.608437\n",
      "[LightGBM] [Info] Number of positive: 999, number of negative: 4996\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000158 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1107\n",
      "[LightGBM] [Info] Number of data points in the train set: 5995, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.166639 -> initscore=-1.609638\n",
      "[LightGBM] [Info] Start training from score -1.609638\n",
      "Mejores hiperparámetros para VotingClassifier: {}\n",
      "Mejor score para VotingClassifier: 0.9956630525437864\n",
      "[LightGBM] [Info] Number of positive: 799, number of negative: 3997\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000154 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1085\n",
      "[LightGBM] [Info] Number of data points in the train set: 4796, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.166597 -> initscore=-1.609938\n",
      "[LightGBM] [Info] Start training from score -1.609938\n",
      "[LightGBM] [Info] Number of positive: 799, number of negative: 3997\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000140 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1085\n",
      "[LightGBM] [Info] Number of data points in the train set: 4796, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.166597 -> initscore=-1.609938\n",
      "[LightGBM] [Info] Start training from score -1.609938\n",
      "[LightGBM] [Info] Number of positive: 799, number of negative: 3997\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000142 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1089\n",
      "[LightGBM] [Info] Number of data points in the train set: 4796, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.166597 -> initscore=-1.609938\n",
      "[LightGBM] [Info] Start training from score -1.609938\n",
      "[LightGBM] [Info] Number of positive: 799, number of negative: 3997\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000203 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1085\n",
      "[LightGBM] [Info] Number of data points in the train set: 4796, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.166597 -> initscore=-1.609938\n",
      "[LightGBM] [Info] Start training from score -1.609938\n",
      "[LightGBM] [Info] Number of positive: 800, number of negative: 3996\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000139 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1074\n",
      "[LightGBM] [Info] Number of data points in the train set: 4796, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.166806 -> initscore=-1.608437\n",
      "[LightGBM] [Info] Start training from score -1.608437\n",
      "[LightGBM] [Info] Number of positive: 799, number of negative: 3997\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000151 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1085\n",
      "[LightGBM] [Info] Number of data points in the train set: 4796, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.166597 -> initscore=-1.609938\n",
      "[LightGBM] [Info] Start training from score -1.609938\n",
      "[LightGBM] [Info] Number of positive: 799, number of negative: 3997\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000147 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1085\n",
      "[LightGBM] [Info] Number of data points in the train set: 4796, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.166597 -> initscore=-1.609938\n",
      "[LightGBM] [Info] Start training from score -1.609938\n",
      "[LightGBM] [Info] Number of positive: 799, number of negative: 3997\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000217 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1089\n",
      "[LightGBM] [Info] Number of data points in the train set: 4796, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.166597 -> initscore=-1.609938\n",
      "[LightGBM] [Info] Start training from score -1.609938\n",
      "[LightGBM] [Info] Number of positive: 799, number of negative: 3997\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000138 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1085\n",
      "[LightGBM] [Info] Number of data points in the train set: 4796, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.166597 -> initscore=-1.609938\n",
      "[LightGBM] [Info] Start training from score -1.609938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 800, number of negative: 3996\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000187 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1074\n",
      "[LightGBM] [Info] Number of data points in the train set: 4796, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.166806 -> initscore=-1.608437\n",
      "[LightGBM] [Info] Start training from score -1.608437\n",
      "[LightGBM] [Info] Number of positive: 799, number of negative: 3997\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000151 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1085\n",
      "[LightGBM] [Info] Number of data points in the train set: 4796, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.166597 -> initscore=-1.609938\n",
      "[LightGBM] [Info] Start training from score -1.609938\n",
      "[LightGBM] [Info] Number of positive: 799, number of negative: 3997\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000149 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1085\n",
      "[LightGBM] [Info] Number of data points in the train set: 4796, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.166597 -> initscore=-1.609938\n",
      "[LightGBM] [Info] Start training from score -1.609938\n",
      "[LightGBM] [Info] Number of positive: 799, number of negative: 3997\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000133 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1089\n",
      "[LightGBM] [Info] Number of data points in the train set: 4796, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.166597 -> initscore=-1.609938\n",
      "[LightGBM] [Info] Start training from score -1.609938\n",
      "[LightGBM] [Info] Number of positive: 799, number of negative: 3997\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000125 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1085\n",
      "[LightGBM] [Info] Number of data points in the train set: 4796, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.166597 -> initscore=-1.609938\n",
      "[LightGBM] [Info] Start training from score -1.609938\n",
      "[LightGBM] [Info] Number of positive: 800, number of negative: 3996\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000129 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1074\n",
      "[LightGBM] [Info] Number of data points in the train set: 4796, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.166806 -> initscore=-1.608437\n",
      "[LightGBM] [Info] Start training from score -1.608437\n",
      "[LightGBM] [Info] Number of positive: 799, number of negative: 3997\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000204 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1085\n",
      "[LightGBM] [Info] Number of data points in the train set: 4796, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.166597 -> initscore=-1.609938\n",
      "[LightGBM] [Info] Start training from score -1.609938\n",
      "[LightGBM] [Info] Number of positive: 799, number of negative: 3997\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000164 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1085\n",
      "[LightGBM] [Info] Number of data points in the train set: 4796, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.166597 -> initscore=-1.609938\n",
      "[LightGBM] [Info] Start training from score -1.609938\n",
      "[LightGBM] [Info] Number of positive: 799, number of negative: 3997\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000145 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1089\n",
      "[LightGBM] [Info] Number of data points in the train set: 4796, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.166597 -> initscore=-1.609938\n",
      "[LightGBM] [Info] Start training from score -1.609938\n",
      "[LightGBM] [Info] Number of positive: 799, number of negative: 3997\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000154 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1085\n",
      "[LightGBM] [Info] Number of data points in the train set: 4796, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.166597 -> initscore=-1.609938\n",
      "[LightGBM] [Info] Start training from score -1.609938\n",
      "[LightGBM] [Info] Number of positive: 800, number of negative: 3996\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000139 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1074\n",
      "[LightGBM] [Info] Number of data points in the train set: 4796, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.166806 -> initscore=-1.608437\n",
      "[LightGBM] [Info] Start training from score -1.608437\n",
      "[LightGBM] [Info] Number of positive: 799, number of negative: 3997\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000215 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1085\n",
      "[LightGBM] [Info] Number of data points in the train set: 4796, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.166597 -> initscore=-1.609938\n",
      "[LightGBM] [Info] Start training from score -1.609938\n",
      "[LightGBM] [Info] Number of positive: 799, number of negative: 3997\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000137 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1085\n",
      "[LightGBM] [Info] Number of data points in the train set: 4796, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.166597 -> initscore=-1.609938\n",
      "[LightGBM] [Info] Start training from score -1.609938\n",
      "[LightGBM] [Info] Number of positive: 799, number of negative: 3997\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000152 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1089\n",
      "[LightGBM] [Info] Number of data points in the train set: 4796, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.166597 -> initscore=-1.609938\n",
      "[LightGBM] [Info] Start training from score -1.609938\n",
      "[LightGBM] [Info] Number of positive: 799, number of negative: 3997\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000149 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1085\n",
      "[LightGBM] [Info] Number of data points in the train set: 4796, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.166597 -> initscore=-1.609938\n",
      "[LightGBM] [Info] Start training from score -1.609938\n",
      "[LightGBM] [Info] Number of positive: 800, number of negative: 3996\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000145 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1074\n",
      "[LightGBM] [Info] Number of data points in the train set: 4796, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.166806 -> initscore=-1.608437\n",
      "[LightGBM] [Info] Start training from score -1.608437\n",
      "[LightGBM] [Info] Number of positive: 799, number of negative: 3997\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000164 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1085\n",
      "[LightGBM] [Info] Number of data points in the train set: 4796, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.166597 -> initscore=-1.609938\n",
      "[LightGBM] [Info] Start training from score -1.609938\n",
      "[LightGBM] [Info] Number of positive: 799, number of negative: 3997\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000144 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1085\n",
      "[LightGBM] [Info] Number of data points in the train set: 4796, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.166597 -> initscore=-1.609938\n",
      "[LightGBM] [Info] Start training from score -1.609938\n",
      "[LightGBM] [Info] Number of positive: 799, number of negative: 3997\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000100 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1089\n",
      "[LightGBM] [Info] Number of data points in the train set: 4796, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.166597 -> initscore=-1.609938\n",
      "[LightGBM] [Info] Start training from score -1.609938\n",
      "[LightGBM] [Info] Number of positive: 799, number of negative: 3997\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000169 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1085\n",
      "[LightGBM] [Info] Number of data points in the train set: 4796, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.166597 -> initscore=-1.609938\n",
      "[LightGBM] [Info] Start training from score -1.609938\n",
      "[LightGBM] [Info] Number of positive: 800, number of negative: 3996\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000133 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1074\n",
      "[LightGBM] [Info] Number of data points in the train set: 4796, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.166806 -> initscore=-1.608437\n",
      "[LightGBM] [Info] Start training from score -1.608437\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 799, number of negative: 3997\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000152 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1085\n",
      "[LightGBM] [Info] Number of data points in the train set: 4796, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.166597 -> initscore=-1.609938\n",
      "[LightGBM] [Info] Start training from score -1.609938\n",
      "[LightGBM] [Info] Number of positive: 799, number of negative: 3997\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000218 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1085\n",
      "[LightGBM] [Info] Number of data points in the train set: 4796, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.166597 -> initscore=-1.609938\n",
      "[LightGBM] [Info] Start training from score -1.609938\n",
      "[LightGBM] [Info] Number of positive: 799, number of negative: 3997\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000149 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1089\n",
      "[LightGBM] [Info] Number of data points in the train set: 4796, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.166597 -> initscore=-1.609938\n",
      "[LightGBM] [Info] Start training from score -1.609938\n",
      "[LightGBM] [Info] Number of positive: 799, number of negative: 3997\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000149 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1085\n",
      "[LightGBM] [Info] Number of data points in the train set: 4796, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.166597 -> initscore=-1.609938\n",
      "[LightGBM] [Info] Start training from score -1.609938\n",
      "[LightGBM] [Info] Number of positive: 800, number of negative: 3996\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000149 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1074\n",
      "[LightGBM] [Info] Number of data points in the train set: 4796, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.166806 -> initscore=-1.608437\n",
      "[LightGBM] [Info] Start training from score -1.608437\n",
      "[LightGBM] [Info] Number of positive: 799, number of negative: 3997\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000141 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1085\n",
      "[LightGBM] [Info] Number of data points in the train set: 4796, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.166597 -> initscore=-1.609938\n",
      "[LightGBM] [Info] Start training from score -1.609938\n",
      "[LightGBM] [Info] Number of positive: 799, number of negative: 3997\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000150 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1085\n",
      "[LightGBM] [Info] Number of data points in the train set: 4796, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.166597 -> initscore=-1.609938\n",
      "[LightGBM] [Info] Start training from score -1.609938\n",
      "[LightGBM] [Info] Number of positive: 799, number of negative: 3997\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000153 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1089\n",
      "[LightGBM] [Info] Number of data points in the train set: 4796, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.166597 -> initscore=-1.609938\n",
      "[LightGBM] [Info] Start training from score -1.609938\n",
      "[LightGBM] [Info] Number of positive: 799, number of negative: 3997\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000150 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1085\n",
      "[LightGBM] [Info] Number of data points in the train set: 4796, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.166597 -> initscore=-1.609938\n",
      "[LightGBM] [Info] Start training from score -1.609938\n",
      "[LightGBM] [Info] Number of positive: 800, number of negative: 3996\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000193 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1074\n",
      "[LightGBM] [Info] Number of data points in the train set: 4796, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.166806 -> initscore=-1.608437\n",
      "[LightGBM] [Info] Start training from score -1.608437\n",
      "[LightGBM] [Info] Number of positive: 799, number of negative: 3997\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000152 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1085\n",
      "[LightGBM] [Info] Number of data points in the train set: 4796, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.166597 -> initscore=-1.609938\n",
      "[LightGBM] [Info] Start training from score -1.609938\n",
      "[LightGBM] [Info] Number of positive: 799, number of negative: 3997\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000182 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1085\n",
      "[LightGBM] [Info] Number of data points in the train set: 4796, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.166597 -> initscore=-1.609938\n",
      "[LightGBM] [Info] Start training from score -1.609938\n",
      "[LightGBM] [Info] Number of positive: 799, number of negative: 3997\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000207 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1089\n",
      "[LightGBM] [Info] Number of data points in the train set: 4796, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.166597 -> initscore=-1.609938\n",
      "[LightGBM] [Info] Start training from score -1.609938\n",
      "[LightGBM] [Info] Number of positive: 799, number of negative: 3997\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000163 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1085\n",
      "[LightGBM] [Info] Number of data points in the train set: 4796, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.166597 -> initscore=-1.609938\n",
      "[LightGBM] [Info] Start training from score -1.609938\n",
      "[LightGBM] [Info] Number of positive: 800, number of negative: 3996\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000143 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1074\n",
      "[LightGBM] [Info] Number of data points in the train set: 4796, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.166806 -> initscore=-1.608437\n",
      "[LightGBM] [Info] Start training from score -1.608437\n",
      "[LightGBM] [Info] Number of positive: 999, number of negative: 4996\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000146 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1107\n",
      "[LightGBM] [Info] Number of data points in the train set: 5995, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.166639 -> initscore=-1.609638\n",
      "[LightGBM] [Info] Start training from score -1.609638\n",
      "Mejores hiperparámetros para LGBMClassifier: {'learning_rate': 0.01, 'num_leaves': 5}\n",
      "Mejor score para LGBMClassifier: 0.9963302752293577\n",
      "Mejores hiperparámetros para XGBClassifier: {'learning_rate': 0.01, 'max_depth': 3}\n",
      "Mejor score para XGBClassifier: 0.9963302752293577\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, VotingClassifier\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Cargo los datos\n",
    "df = pd.read_csv('FlightDelays_Data_3.0.csv')\n",
    "\n",
    "# Manejo de variables categoricas y valores faltantes\n",
    "categorical_cols = [\"UniqueCarrier\"]\n",
    "df = pd.get_dummies(df, columns=categorical_cols)\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Separo target y features\n",
    "X = df.drop(\"Canceled\", axis=1)\n",
    "y = df[\"Canceled\"]\n",
    "\n",
    "# Defino los modelos y los hiperparámetros a buscar\n",
    "models = {\n",
    "    'BaggingClassifier': (BaggingClassifier(), {'n_estimators': [10, 50, 100]}),\n",
    "    'DecisionTreeClassifier': (DecisionTreeClassifier(), {'max_depth': [3, 5, 7]}),\n",
    "    'HistGradientBoostingClassifier': (HistGradientBoostingClassifier(), {'learning_rate': [0.001, 0.01, 0.1], 'max_depth': [3, 5, 7]}),\n",
    "    'RandomForestClassifier': (RandomForestClassifier(), {'n_estimators': [10, 50, 100]}),\n",
    "    'StackingClassifier': (StackingClassifier(estimators=[('rf', RandomForestClassifier()), ('svc', SVC())]), {}),\n",
    "    'VotingClassifier': (VotingClassifier(estimators=[('xgb', XGBClassifier()), ('lgbm', LGBMClassifier())]), {}),\n",
    "    'LGBMClassifier': (LGBMClassifier(), {'num_leaves': [5, 10, 15], 'learning_rate': [0.001, 0.01, 0.1]}),\n",
    "    'XGBClassifier': (XGBClassifier(), {'learning_rate': [0.001, 0.01, 0.1], 'max_depth': [3, 5, 7]})\n",
    "}\n",
    "\n",
    "# Itero sobre los modelos\n",
    "for name, (model, param_grid) in models.items():\n",
    "    # Aplico GridSearchCV\n",
    "    grid_search = GridSearchCV(model, param_grid, cv=5)\n",
    "    grid_search.fit(X, y)\n",
    "    \n",
    "    # Obtengo el mejor modelo\n",
    "    best_model = grid_search.best_estimator_\n",
    "    \n",
    "    # Imprimo los hiperparámetros del mejor modelo\n",
    "    print(f\"Mejores hiperparámetros para {name}: {grid_search.best_params_}\")\n",
    "    \n",
    "    # Imprimo el score del mejor modelo\n",
    "    print(f\"Mejor score para {name}: {grid_search.best_score_}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "56ed0251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Feature  Importance\n",
      "4          DepDelay     0.56691\n",
      "3          ArrDelay     0.43309\n",
      "0             Month     0.00000\n",
      "1     DepartureTime     0.00000\n",
      "2  SchedElapsedTime     0.00000\n",
      "5          Distance     0.00000\n",
      "6  UniqueCarrier_AA     0.00000\n",
      "7  UniqueCarrier_DL     0.00000\n",
      "8  UniqueCarrier_UA     0.00000\n"
     ]
    }
   ],
   "source": [
    "# Obtener la importancia de las características\n",
    "feature_importance = best_model.feature_importances_\n",
    "\n",
    "# Crear un DataFrame para mostrar las características y su importancia\n",
    "feature_importance_df = pd.DataFrame({'Feature': X.columns, 'Importance': feature_importance})\n",
    "\n",
    "# Ordenar las características por importancia\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Imprimir la tabla de importancia de características\n",
    "print(feature_importance_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7e2820cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "# Crear un DataFrame con los datos de entrada\n",
    "input_data = pd.DataFrame([[12, 814, 134, 0, 0, 679, 0, 0, 1]], columns=X.columns)\n",
    "\n",
    "# Realizar la predicción\n",
    "prediction = best_model.predict(input_data)\n",
    "\n",
    "# Imprimir la predicción\n",
    "print(prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
